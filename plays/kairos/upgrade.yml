---
- hosts: kairos
  gather_facts: false
  order: sorted
  tasks:
    - name: Ensure configuration is up-to-date
      ansible.builtin.template:
        dest: /oem/90_custom.yaml
        src: templates/config.yml.j2
      become: yes
      register: config
      vars:
        host: "{{ inventory_hostname }}"
    # If the config changes, including files that should no longer exist, we want to make sure the new config is what applies.
    - name: Remove old network files
      block:
        - name: Collect all network configuration files
          ansible.builtin.find:
            paths: /etc/systemd/network/
          register: collected_network_files
        - name: Remove all collected network files
          ansible.builtin.file:
            path: "{{ item.path }}"
            state: absent
          become: yes
          loop: "{{ collected_network_files.files }}"
          loop_control:
            label: "{{ item.path }}"
      when: config.changed
    - name: Read in current version
      ansible.builtin.slurp:
        src: /etc/os-release
      register: osreleasefile
    - name: Decode release metadata
      ansible.builtin.set_fact:
        contents: "{{ osreleasefile['content'] | b64decode }}"
    - name: Extract metadata
      ansible.builtin.set_fact:
        # ex: 22.04-standard-amd64-generic-v2.5.0-k3sv1.27.9-k3s1
        os_image_label: '{{ contents | regex_findall(''^KAIROS_IMAGE_LABEL="(.*)"$'', multiline=True) | last }}'
    - name: Print os image
      ansible.builtin.debug:
        var: os_image_label
    - name: Print target image
      ansible.builtin.debug:
        var: target_image_label
    - name: Install update
      ansible.builtin.command:
        argv:
          - kairos-agent
          - upgrade
          - --source
          - "oci:quay.io/kairos/ubuntu:{{ target_image_label }}"
      become: true
      when: os_image_label != target_image_label
    - name: Note if the host needs to be rebooted
      ansible.builtin.set_fact:
        reboot_required: "{{ os_image_label != target_image_label or config.changed }}"
    - name: Schedule Drain and Reboot
      ansible.builtin.add_host:
        name: "{{ item }}"
        group: ToReboot
      changed_when: no
      delegate_to: localhost
      loop: "{{ ansible_play_batch }}"
      when: hostvars[item].reboot_required
  vars:
    target_image_label: 22.04-standard-amd64-generic-v2.5.0-k3sv1.28.5-k3s1

- name: Serially drain and reboot hosts that need to be rebooted
  hosts: ToReboot
  gather_facts: no
  order: sorted
  serial:
    - 1 # This will always be the first control plane node.
    - 1 # This will be the second node.
    - 3 # The remaining nodes in chunks of three.
  strategy: free
  tasks:
    # TODO(sdwilsh): This does not work today because we need to be able to select specific pods.  See
    #                https://github.com/ansible-collections/kubernetes.core/issues/474
    # - name: Drain
    #   kubernetes.core.k8s_drain:
    #     delete_options:
    #       delete_emptydir_data: yes
    #       force: yes
    #       ignore_daemonsets: yes
    #     name: "{{ inventory_hostname_short }}"
    #     state: drain
    #   delegate_to: localhost
    - name: Drain
      ansible.builtin.shell:
        cmd: "kubectl drain {{ inventory_hostname_short }} --ignore-daemonsets --delete-emptydir-data --force --pod-selector='{{ pod_selectors | join(',') }}' --kubeconfig ~/.kube/config"
      delegate_to: localhost
      vars:
        pod_selectors:
          - app!=csi-attacher
          - app!=csi-provisioner
          - longhorn.io/instance-manager-type!=engine
          - longhorn.io/instance-manager-type!=replica
    - name: Reboot
      ansible.builtin.reboot:
        pre_reboot_delay: 60 # seconds
        connect_timeout: 240 # seconds
        test_command: "{{ reboot_test_command }}"
      become: yes
    - name: Uncordon
      kubernetes.core.k8s_drain:
        name: "{{ inventory_hostname_short }}"
        state: uncordon
      delegate_to: localhost
